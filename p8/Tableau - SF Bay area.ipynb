{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as re\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Clean & combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_values(df, column):\n",
    "    # remove + (2,000+) and - (missing values) signs\n",
    "    df[column] = df[column].map(lambda x: x.rstrip('+-N'))\n",
    "\n",
    "    # remove , in 2,000+\n",
    "    df[column] = df[column].astype(str).map(lambda x: re.sub(r'[,]', '', x))\n",
    "    \n",
    "    # replace empty values with NaN\n",
    "    df[column] = df[column].apply(lambda x: x.strip()).replace('', np.nan)\n",
    "    \n",
    "    return df[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_csv(name, year):    \n",
    "    # upload data\n",
    "    df = pd.read_csv(name, header = 1)\n",
    "    \n",
    "    # create new column with 11 digit tract code\n",
    "    df['tract_id'] = df['Id'].str[-11:]\n",
    "\n",
    "    # add column for year\n",
    "    df['year'] = year\n",
    "    \n",
    "    if 'DP04' in name:\n",
    "        # rename column names\n",
    "        df = df.rename(index = str, \n",
    "                         columns = {'Estimate; GROSS RENT - Occupied units paying rent - Median (dollars)': \n",
    "                                    'median_rent', \n",
    "                                    'Estimate; GROSS RENT - Median (dollars)': 'median_rent',\n",
    "                                    'Estimate; VALUE - Owner-occupied units - Median (dollars)': \\\n",
    "                                    'median_house_price',\n",
    "                                    'Estimate; VALUE - Median (dollars)': 'median_house_price',\n",
    "                                    'Estimate; VALUE - Owner-occupied units - $1,000,000 or more': 'over_mln',\n",
    "                                    'Estimate; VALUE - $1,000,000 or more': 'over_mln',\n",
    "                                    'Estimate; HOUSING OCCUPANCY - Occupied housing units': 'housing_units',\n",
    "                                    'Estimate; HOUSING OCCUPANCY - Total housing units - Occupied housing units': \n",
    "                                    'housing_units',\n",
    "                                    'Estimate; GROSS RENT - Occupied units paying rent - $1,500 or more': \\\n",
    "                                    'over_1500',\n",
    "                                    'Estimate; GROSS RENT - Occupied units paying rent - $1,500 to $1,999' : \\\n",
    "                                    '1500-1999',\n",
    "                                    'Estimate; GROSS RENT - Occupied units paying rent - $2,000 to $2,499': \\\n",
    "                                    'over 2000',\n",
    "                                    'Estimate; GROSS RENT - Occupied units paying rent - $2,500 to $2,999': \\\n",
    "                                    'over 2500',\n",
    "                                    'Estimate; GROSS RENT - Occupied units paying rent - $3,000 or more' : \\\n",
    "                                    'over 3000',\n",
    "                                    'Estimate; GROSS RENT - $1,500 or more': 'over_1500',\n",
    "                                    'Estimate; GROSS RENT - Occupied units paying rent' : 'paid_rented_units',\n",
    "                                    'Estimate; GROSS RENT - No rent paid' : 'unpaid_rented_units',                                    \n",
    "                                    'Estimate; VALUE - Owner-occupied units' : 'owned_units'\n",
    "                                    })\n",
    "        \n",
    "        # combine paid and unpaid to get total rented units\n",
    "        df['rented_units'] = df['paid_rented_units'] + df['unpaid_rented_units']\n",
    "        \n",
    "        # combine the over $1,500 buckets for 2016 in order to compare with the other years\n",
    "        if '_16_' in name:\n",
    "            df['over_1500'] = df['1500-1999'] + df['over 2000'] + df['over 2500'] + df['over 3000']\n",
    "            \n",
    "        else:\n",
    "            df = df\n",
    "            \n",
    "        # remove sign (+-,) from column values so that they can be converted to numbers\n",
    "        df['median_rent'] = clean_values(df, 'median_rent')\n",
    "        df['median_house_price'] = clean_values(df, 'median_house_price')\n",
    "        \n",
    "        # add column to adjust rents in 2016, to same ceiling of 2,000 dollar\n",
    "        df['median_rent_adj'] = df.apply(lambda row: 2000 if pd.to_numeric(row['median_rent']) >=2000 \\\n",
    "                         else row['median_rent'], axis=1) \n",
    "        \n",
    "        # add column to adjust house prices in 2016, to same ceiling of 1,000,000 dollar\n",
    "        df['median_hp_adj'] = df.apply(lambda row: 1000000 if pd.to_numeric(row['median_house_price']) >=1000000 \\\n",
    "                         else row['median_house_price'], axis=1) \n",
    "        \n",
    "        # keep only needed columns\n",
    "        df2 = df[['tract_id', 'year', 'median_rent', 'median_rent_adj', 'median_house_price', 'median_hp_adj', \\\n",
    "                  'housing_units', 'rented_units', 'owned_units', 'over_mln', 'over_1500',]]\n",
    "    \n",
    "    elif 'S1901' in name:\n",
    "        # rename median income column \n",
    "        df = df.rename(columns = {'Households; Estimate; Median income (dollars)': 'median_income'})\n",
    "        \n",
    "        # remove sign (+-,) from column values so that they can be converted to numbers\n",
    "        df['median_income'] = clean_values(df, 'median_income')      \n",
    "        \n",
    "        # (no adjustment needed as ceiling for 2016 is the same as for other years)\n",
    "        \n",
    "        # keep only needed columns\n",
    "        df2 = df[['tract_id', 'year', 'median_income']]\n",
    "    \n",
    "    elif 'S0801' in name:        \n",
    "        # replace cells with '-' with ''\n",
    "        df = df.apply(lambda x: x.replace('-', ''))\n",
    "        \n",
    "        # calculate % of people who commute equal or longer than 30 minutes\n",
    "        df['more_30'] = pd.to_numeric(df['Total; Estimate; TRAVEL TIME TO WORK - 30 to 34 minutes'])+ \\\n",
    "        pd.to_numeric(df['Total; Estimate; TRAVEL TIME TO WORK - 35 to 44 minutes']) + \\\n",
    "        pd.to_numeric(df['Total; Estimate; TRAVEL TIME TO WORK - 45 to 59 minutes']) + \\\n",
    "        pd.to_numeric(df['Total; Estimate; TRAVEL TIME TO WORK - 60 or more minutes'])\n",
    "                \n",
    "        # rename mean commuting column\n",
    "        df = df.rename(columns = {'Total; Estimate; TRAVEL TIME TO WORK - Mean travel time to work (minutes)' : \n",
    "                                  'mean_commute',\n",
    "                                  'Total; Estimate; TRAVEL TIME TO WORK - 60 or more minutes' : 'more_60'\n",
    "                                 })\n",
    "        \n",
    "        # remove sign (+-,) from column values so that they can be converted to numbers\n",
    "        df['mean_commute'] = clean_values(df, 'mean_commute')\n",
    "        \n",
    "        # keep only needed columns\n",
    "        df2 = df[['tract_id', 'year', 'mean_commute', 'more_30', 'more_60']]\n",
    "        \n",
    "    elif 'B01003' in name:\n",
    "        # rename population column\n",
    "        df = df.rename(columns = {'Estimate; Total' : 'population'})\n",
    "        \n",
    "        # keep only needed columns\n",
    "        df2 = df[['tract_id', 'year', 'population']]\n",
    "        \n",
    "    else:\n",
    "        df2 = df\n",
    "        \n",
    "    df2 = df2.applymap(str)\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# commuting\n",
    "commuting_2016 = clean_csv('ACS_16_5YR_S0801_with_ann.csv', '2016')\n",
    "commuting_2013 = clean_csv('ACS_13_5YR_S0801_with_ann.csv', '2013')\n",
    "commuting_2010 = clean_csv('ACS_10_5YR_S0801_with_ann.csv', '2010')\n",
    "\n",
    "commuting = [commuting_2016, commuting_2013, commuting_2010]\n",
    "\n",
    "# concatenate dfs\n",
    "all_commuting = pd.concat(commuting, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# housing\n",
    "housing_2016 = clean_csv('ACS_16_5YR_DP04_with_ann.csv', '2016')\n",
    "housing_2013 = clean_csv('ACS_13_5YR_DP04_with_ann.csv', '2013')\n",
    "housing_2010 = clean_csv('ACS_10_5YR_DP04_with_ann.csv', '2010')\n",
    "\n",
    "housing = [housing_2016, housing_2013, housing_2010]\n",
    "\n",
    "# concatenate dfs\n",
    "all_housing = pd.concat(housing, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# income\n",
    "income_2010 = clean_csv('ACS_10_5YR_S1901_with_ann.csv', '2010')\n",
    "income_2013 = clean_csv('ACS_13_5YR_S1901_with_ann.csv', '2013')\n",
    "income_2016 = clean_csv('ACS_16_5YR_S1901_with_ann.csv', '2016')\n",
    "\n",
    "income = [income_2016, income_2013, income_2010]\n",
    "\n",
    "# concatenate dfs\n",
    "all_income = pd.concat(income, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# population\n",
    "population_2010 = clean_csv('ACS_10_5YR_B01003_with_ann.csv', '2010')\n",
    "population_2013 = clean_csv('ACS_13_5YR_B01003_with_ann.csv', '2013')\n",
    "population_2016 = clean_csv('ACS_16_5YR_B01003_with_ann.csv', '2016')\n",
    "\n",
    "population = [population_2016, population_2013, population_2010]\n",
    "\n",
    "# concatenate dfs\n",
    "all_population = pd.concat(population, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine dfs\n",
    "dfs = [all_housing, all_commuting, all_income, all_population]\n",
    "\n",
    "df_all = reduce(lambda left, right: pd.merge(left, right , on = ['tract_id', 'year']), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column with number of people per housing unit\n",
    "df_all['people_per_unit'] = pd.to_numeric(df_all['population']) / pd.to_numeric(df_all['housing_units'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create df with all current tract ids\n",
    "tracts = df_all[df_all.year == '2010']['tract_id'].to_frame()\n",
    "#tracts = tracts.rename(columns = {'tract_id' : 'id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Calculate changes between 2010 and 2016 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_changes(tables, name, column2016, column2010, id, drop):\n",
    "    # merge so there is one row per tract id\n",
    "    dfs = reduce(lambda left,right: pd.merge(left, right , on = [id]), tables)\n",
    "    \n",
    "    if drop == True:\n",
    "        # replace empty cells with NaN\n",
    "        dfs = dfs.apply(lambda x: x.str.strip()).replace('', np.nan)\n",
    "        \n",
    "        dfs = dfs.apply(lambda x: x.str.strip()).replace('nan', np.nan)\n",
    "    \n",
    "        # drop rows with an empty values\n",
    "        dfs = dfs.dropna()\n",
    "    \n",
    "    # calculate change between 2016 and 2010\n",
    "    if name in ['rent_change', 'price_change', 'comm_change', 'y_change', 'rent_adj_change', 'price_adj_change', 'y_adj_change']:\n",
    "        dfs[name] = ((pd.to_numeric(dfs[column2016]) - pd.to_numeric(dfs[column2010])) / \\\n",
    "                     pd.to_numeric(dfs[column2010])) * 100\n",
    "    \n",
    "    else:\n",
    "        dfs[name] = pd.to_numeric(dfs[column2016]) - pd.to_numeric(dfs[column2010])\n",
    "    \n",
    "    if name in ['rent_adj_change', 'price_adj_change', 'y_change']:\n",
    "        dfs = dfs[[id, name, column2010]]\n",
    "    \n",
    "    else:\n",
    "        dfs = dfs[[id, name]]\n",
    "    \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate changes in values\n",
    "df1 = get_changes(housing, 'rent_change', 'median_rent_x', 'median_rent', 'tract_id', True)\n",
    "df2 = get_changes(housing, 'rent_adj_change', 'median_rent_adj_x', 'median_rent_adj', 'tract_id', True)\n",
    "#df2 = get_changes(housing, '1500_change', 'over_1500_%_x', 'over_1500_%', 'tract_id', True)\n",
    "df3 = get_changes(housing, 'price_change', 'median_house_price_x', 'median_house_price', 'tract_id', True)\n",
    "df4 = get_changes(housing, 'price_adj_change', 'median_hp_adj_x', 'median_hp_adj', 'tract_id', True)\n",
    "#df4 = get_changes(housing, 'mln_change', 'mln_%_x', 'mln_%', 'tract_id', True)\n",
    "df5 = get_changes(commuting, 'comm_30_change', 'more_30_x', 'more_30', 'tract_id', True)\n",
    "df6 = get_changes(commuting, 'comm_60_change','more_60_x', 'more_60', 'tract_id', True)\n",
    "df7 = get_changes(commuting, 'comm_change', 'mean_commute_x', 'mean_commute', 'tract_id', True)\n",
    "df8 = get_changes(income, 'y_change', 'median_income_x', 'median_income', 'tract_id', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rianne/anaconda3/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# add column to show which values are the max recorded value for that variable\n",
    "def ceiling(df, name, change, amount, max):\n",
    "    # isolate rows that have the max amount and no change between 2010 and 2016\n",
    "    dfa = df[((pd.to_numeric(df[name])) == amount) & (df[change] == 0.0)]\n",
    "    \n",
    "    # add column max\n",
    "    dfa['max'] = max\n",
    "    \n",
    "    # combine dfa with original df\n",
    "    dfb = df.merge(dfa[['tract_id','max']], on = 'tract_id', how = 'left')\n",
    "    \n",
    "    return dfb\n",
    "\n",
    "# add for nerent, house price and income columns\n",
    "df2_ = ceiling(df2, 'median_rent_adj', 'rent_adj_change', 2000, 'max_rent')\n",
    "df4_ = ceiling(df4, 'median_hp_adj', 'price_adj_change', 1000000, 'max_price')\n",
    "df8_ = ceiling(df8, 'median_income', 'y_change', 2500000, 'max_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column for low income tracts\n",
    "df8_['low'] = df8_.apply(lambda row: 'low' if pd.to_numeric(row['median_income']) < 60000 \\\n",
    "                         else '', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list dfs\n",
    "dfs = [tracts, df1, df2_, df3, df4_, df5, df6, df7, df8_] \n",
    "\n",
    "# join all dfs\n",
    "all_changes = reduce(lambda left, right: pd.merge(left, right , on = 'tract_id', how = 'left'), dfs)\n",
    "\n",
    "# add new columns to mother df\n",
    "df_all = df_all.merge(all_changes, on = ['tract_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Mapping tracts to counties</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uploading mapping of county ids to county names\n",
    "coding = pd.read_csv('coding.csv', header = None, names = ['state_name', 'state', 'county', 'county_name', 'random'])\n",
    "\n",
    "# add leading zeros to get a 2 digit state id and a 3 digit county id\n",
    "coding['state'] = coding['state'].astype(str).str.rjust(2,'0')\n",
    "coding['county'] = coding['county'].astype(str).str.rjust(3,'0')\n",
    "\n",
    "# add column with the combination of state and county ids\n",
    "coding['county_id'] = coding['state'] + coding['county']\n",
    "\n",
    "# only keeping id and county name columns\n",
    "county = coding[['county_id', 'county_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extact 6 digit country code\n",
    "df_all['county_id'] = df_all['tract_id'].str[:5]\n",
    "\n",
    "# merge with county mapping df\n",
    "df_all = df_all.merge(county, on = 'county_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list with all county ids\n",
    "county_ids = df_all.county_id.unique().tolist()\n",
    "#county_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>NEW - Mapping tracts to cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# upload new tract id cities mapping from http://proximityone.com/tract_place.htm\n",
    "cities_new = pd.read_csv('cities_new.csv')\n",
    "\n",
    "# add leading 0 to tract ids\n",
    "cities_new['tract_id'] = cities_new['tract_id'].astype(str).map(lambda x: '0' + x)\n",
    "\n",
    "# get tract ids for San Francisco (faster this way)\n",
    "#sf = df_all[(df_all.tract_id.str[:5] == '06075') & (df_all.year == 2016)]['tract_id'].to_frame()\n",
    "sf = tracts[tracts.tract_id.str[:5] == '06075']['tract_id'].to_frame()\n",
    "\n",
    "# add column for city name\n",
    "sf['city'] = 'San Francisco'\n",
    "\n",
    "sf = sf.reset_index(drop = True)\n",
    "\n",
    "# combine new_cities and sf\n",
    "new_cities = cities_new.append(sf, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with city mapping df\n",
    "df_all = df_all.merge(new_cities, on = 'tract_id', how = 'left')\n",
    "\n",
    "# remove ' County' from county_name\n",
    "df_all['county_name'] = df_all['county_name'].map(lambda x: x.rstrip('County'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Tracts assigned to multiple cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find tract ids that are assigned to multiple cities\n",
    "mul_cities = df_all.groupby(['tract_id'], as_index = False).count()[['tract_id','city']]\n",
    "\n",
    "# filter out that show up more than 3 (looking at 3 years) & merge with df_all\n",
    "mul_cities = (mul_cities[mul_cities.city > 3]).merge(df_all[['tract_id', 'city']], on ='tract_id', how = 'left')\n",
    "\n",
    "# drop duplicate rows\n",
    "mul_cities = mul_cities.drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tract_id</th>\n",
       "      <th>city_x</th>\n",
       "      <th>city_y</th>\n",
       "      <th>all_cities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06001409300</td>\n",
       "      <td>6</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>Oakland, San Leandro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06001438000</td>\n",
       "      <td>6</td>\n",
       "      <td>Hayward</td>\n",
       "      <td>Hayward, Union City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06001450601</td>\n",
       "      <td>6</td>\n",
       "      <td>Hayward</td>\n",
       "      <td>Hayward, Pleasanton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>06001450752</td>\n",
       "      <td>6</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>Dublin, Livermore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>06013303102</td>\n",
       "      <td>6</td>\n",
       "      <td>Brentwood</td>\n",
       "      <td>Brentwood, Oakley</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tract_id  city_x     city_y            all_cities\n",
       "0  06001409300       6    Oakland  Oakland, San Leandro\n",
       "2  06001438000       6    Hayward   Hayward, Union City\n",
       "4  06001450601       6    Hayward   Hayward, Pleasanton\n",
       "6  06001450752       6     Dublin     Dublin, Livermore\n",
       "8  06013303102       6  Brentwood     Brentwood, Oakley"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine names of cities assigned to same tract ids in column 'all_cities'\n",
    "for i in range(len(mul_cities)-1):\n",
    "    # combine 2 city names\n",
    "    if (mul_cities.loc[i, 'city_x'] == 6) & (mul_cities.loc[i, 'tract_id'] == mul_cities.loc[i+1, 'tract_id']):\n",
    "        mul_cities.loc[i, 'all_cities'] = mul_cities.loc[i, 'city_y'] + ', ' + mul_cities.loc[i+1, 'city_y']\n",
    "    # combine 3 city names\n",
    "    elif (mul_cities.loc[i, 'city_x'] == 9) & \\\n",
    "    (mul_cities.loc[i, 'tract_id'] == mul_cities.loc[i+1, 'tract_id'] == mul_cities.loc[i+2, 'tract_id']):\n",
    "        mul_cities.loc[i, 'all_cities'] = mul_cities.loc[i, 'city_y'] + ', ' + mul_cities.loc[i+1, 'city_y'] + ', ' + mul_cities.loc[i+2, 'city_y'] \n",
    "    # combine 4 city names\n",
    "    elif (mul_cities.loc[i, 'city_x'] == 12) & (mul_cities.loc[i, 'tract_id'] == mul_cities.loc[i+1, 'tract_id'] == mul_cities.loc[i+2, 'tract_id'] == mul_cities.loc[i+3, 'tract_id']):\n",
    "        mul_cities.loc[i, 'all_cities'] = mul_cities.loc[i, 'city_y'] + ', ' + mul_cities.loc[i+1, 'city_y'] + ', ' + mul_cities.loc[i+2, 'city_y'] + ', ' + mul_cities.loc[i+3, 'city_y']\n",
    "    else:\n",
    "        mul_cities.loc[i, 'all_cities'] = ''\n",
    "    \n",
    "        \n",
    "# keep only rows that have values in the 'all_cities' column\n",
    "mul_cities =  mul_cities[mul_cities.all_cities != '']\n",
    "mul_cities.dropna(axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = df_all.merge(mul_cities[['tract_id', 'all_cities']], on ='tract_id', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Find tract ids from lat/lng coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api from https://geo.fcc.gov/api/census/\n",
    "# code based on https://pypkg.com/pypi/fcc/f/fcc/census_block_conversions.py\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def census_block(latitude, longitude):\n",
    "    '''Get the FCC API response in the specified text format.'''\n",
    "    base_url = 'https://geo.fcc.gov/api/census/area?format=json&{lat}{lng}'\n",
    "\n",
    "\n",
    "    parameters = {\n",
    "        'lat': 'lat=' + str(latitude),\n",
    "        'lng': '&lon=' + str(longitude)\n",
    "    }\n",
    "    \n",
    "    data = requests.get(base_url.format(**parameters)).text\n",
    "\n",
    "    return data\n",
    "\n",
    "def census_block_dict(latitude, longitude):\n",
    "    '''Get the FCC API response as a Python dictionary.'''\n",
    "    return json.loads(census_block(latitude, longitude))\n",
    "\n",
    "\n",
    "def census_block_fips(latitude, longitude):\n",
    "    '''\n",
    "    Get only the census block FIPS code.\n",
    "    Only return the first if the location corresponds to more than one code.\n",
    "    '''\n",
    "    return census_block_dict(latitude, longitude)['results'][0]['block_fips']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read csv with largest cities with their population in CA\n",
    "df = pd.read_csv('ca_cities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add type column\n",
    "df['type'] = 'city'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column with census block id in df\n",
    "df['GEOID'] = df.apply(lambda x: census_block_fips(x['lat'], x['long']), axis=1)\n",
    "\n",
    "# get 11 digit tract id\n",
    "df['GEOID'] = df['GEOID'].str[:11]\n",
    "\n",
    "# get 5 digit county id\n",
    "df['county_id'] = df['GEOID'].str[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['name'] = df['name'].astype(str).map(lambda x: x.rstrip(' CA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = df[['name', 'lat','lng','GEOID', 'pop','county_id', 'type']]\n",
    "\n",
    "cities = cities.merge(coding, on = 'county_id', how = 'left')\n",
    "\n",
    "cities['county_name'] = cities['county_name'].astype(str).map(lambda x: x.rstrip('County'))\n",
    "\n",
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# upload centers of countries in order to combine them with cities\n",
    "county_coord = pd.read_csv('county_coord.csv')\n",
    "\n",
    "# add county ids\n",
    "county_ids_list = ['06001', '06013', '06041', '06055', '06075', '06081', '06085', '06095', '06097'] \n",
    "ids = pd.Series(county_ids_list)\n",
    "county_coord = county_coord.assign(county_id = ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only get cities in the SF Bay area\n",
    "cities = cities.loc[cities['county_id'].isin(county_ids_list)]\n",
    "\n",
    "# combine city and county lat/lng coordinates\n",
    "cities_counties = pd.concat([county_coord, cities], ignore_index = True)\n",
    "cities_counties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = ExcelWriter('cities_counties.xls')\n",
    "cities_counties.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# upload company addresses in the SF Bay area from Google spreadsheet\n",
    "companies = pd.read_csv('https://docs.google.com/spreadsheets/d/' +\n",
    "                        '1xaDnlKJiUduQCz7g8SDJIBRTtOgHPtEJyy7RqUtfZyM/' +\n",
    "                        'export?gid=0&format=csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coordinates(address):\n",
    "    base_url = 'https://maps.googleapis.com/maps/api/geocode/json?{address}&key=AIzaSyBuNCslUVUdtRDx5kITaEvbb2Hf_wuQgVQ'\n",
    "\n",
    "    parameters = {'address': 'address=' + str(address)}\n",
    "    \n",
    "    data = requests.get(base_url.format(**parameters)).text\n",
    "    \n",
    "    # create python dictionary\n",
    "    dictionary = json.loads(data)\n",
    "    \n",
    "    # extract coordinates\n",
    "    coordinates = dictionary['results'][0]['geometry']['location']\n",
    "    return coordinates\n",
    "\n",
    "def lat_coord(address):\n",
    "    lat = coordinates(address)['lat']\n",
    "    return lat\n",
    "    \n",
    "def lng_coord(address):\n",
    "    lng = coordinates(address)['lng']\n",
    "    return lng  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add column with lat coordinates\n",
    "companies['lat'] = companies.apply(lambda x: \n",
    "                                   lat_coord(x['address']), axis=1)\n",
    "\n",
    "# add column with lng coordinates\n",
    "companies['lng'] = companies.apply(lambda x: \n",
    "                                   lng_coord(x['address']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create column with census block id \n",
    "companies['GEOID'] = companies.apply(lambda x: \n",
    "                                     census_block_fips(x['lat'], x['lng']),\n",
    "                                     axis=1)\n",
    "\n",
    "# get 11 digit census tract\n",
    "companies['GEOID'] = companies['GEOID'].str[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop address column\n",
    "companies.drop('address', axis = 1, inplace = True)\n",
    "\n",
    "# insert pop column (in order to be able to union in Tableau)\n",
    "#companies.insert(1, 'pop', 0)\n",
    "\n",
    "# add type column\n",
    "companies['type'] = 'company'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_excel_2(df1, df2, name_xls, name1, name2):\n",
    "    writer = ExcelWriter(name_xls)\n",
    "    df1.to_excel(writer, sheet_name = name1)\n",
    "    df2.to_excel(writer, sheet_name = name2)\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_excel_2(df, companies, 'cities_companies.xls', 'cities', 'companies')              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Bart stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://api.bart.gov/api/stn.aspx?cmd=stns&key=MW9S-E7SL-26DU-VV8V&json=y'\n",
    "\n",
    "data = requests.get(url).text\n",
    "\n",
    "bart = json.loads(data)\n",
    "\n",
    "stations = bart['root']['stations']['station']\n",
    "\n",
    "list_stations = []\n",
    "for station in stations:\n",
    "    location = [station['name'],station['gtfs_longitude'],station['gtfs_latitude']]\n",
    "    list_stations.append(location)\n",
    "    \n",
    "df = pd.DataFrame(list_stations, columns= ['name', 'long', 'lat'])\n",
    "df['type'] = 'bart'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Caltrain stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caltrain locations from http://www.caltrain.com/developer.html\n",
    "train = pd.read_csv('caltrain_stops.txt')\n",
    "\n",
    "# keep only one instance per station\n",
    "train = train[train.stop_id.astype(str).str[-1:] == '1']\n",
    "\n",
    "# remove Caltrain from the names\n",
    "train['stop_name'] = train.stop_name.str.split(' Caltrain').str.get(0)\n",
    "\n",
    "# only keep needed columns\n",
    "train = train[['stop_name', 'stop_lat', 'stop_lon']]\n",
    "\n",
    "# rename columns\n",
    "train = train.rename(columns={'stop_name':'name', 'stop_lat': 'lat', 'stop_lon': 'long'})\n",
    "\n",
    "# change type so that it is the same as the bart data\n",
    "#train['lat'] = train['lat'].astype(object)\n",
    "#train['long'] = train['long'].astype(object)\n",
    "\n",
    "# add column for type\n",
    "train['type'] = 'caltrain'\n",
    "\n",
    "train = train.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.7764</td>\n",
       "      <td>-122.395</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>caltrain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.7576</td>\n",
       "      <td>-122.392</td>\n",
       "      <td>22nd St</td>\n",
       "      <td>caltrain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.7095</td>\n",
       "      <td>-122.402</td>\n",
       "      <td>Bayshore</td>\n",
       "      <td>caltrain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.6559</td>\n",
       "      <td>-122.405</td>\n",
       "      <td>South San Francisco</td>\n",
       "      <td>caltrain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.6311</td>\n",
       "      <td>-122.412</td>\n",
       "      <td>San Bruno</td>\n",
       "      <td>caltrain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lat     long                 name      type\n",
       "0  37.7764 -122.395        San Francisco  caltrain\n",
       "1  37.7576 -122.392              22nd St  caltrain\n",
       "2  37.7095 -122.402             Bayshore  caltrain\n",
       "3  37.6559 -122.405  South San Francisco  caltrain\n",
       "4  37.6311 -122.412            San Bruno  caltrain"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine bart and caltrain data\n",
    "transport = pd.concat([train,df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column with census block id in df\n",
    "transport['GEOID'] = transport.apply(lambda x: census_block_fips(x['lat'], x['long']), axis=1)\n",
    "\n",
    "# get 11 digit tract id\n",
    "transport['tract_id'] = transport['GEOID'].str[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine with df_all\n",
    "df_all = df_all.merge(transport[['lat', 'long', 'name', 'type', 'tract_id']], on = 'tract_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tract_id</th>\n",
       "      <th>year</th>\n",
       "      <th>median_rent</th>\n",
       "      <th>median_rent_adj_x</th>\n",
       "      <th>median_house_price</th>\n",
       "      <th>median_hp_adj_x</th>\n",
       "      <th>housing_units</th>\n",
       "      <th>rented_units</th>\n",
       "      <th>owned_units</th>\n",
       "      <th>over_mln</th>\n",
       "      <th>...</th>\n",
       "      <th>max</th>\n",
       "      <th>low</th>\n",
       "      <th>county_id</th>\n",
       "      <th>county_name</th>\n",
       "      <th>city</th>\n",
       "      <th>all_cities</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06001400100</td>\n",
       "      <td>2016</td>\n",
       "      <td>3202</td>\n",
       "      <td>2000</td>\n",
       "      <td>1074100</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1292</td>\n",
       "      <td>128</td>\n",
       "      <td>1164</td>\n",
       "      <td>665</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>06001</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06001400200</td>\n",
       "      <td>2016</td>\n",
       "      <td>1770</td>\n",
       "      <td>1770</td>\n",
       "      <td>978900</td>\n",
       "      <td>978900</td>\n",
       "      <td>813</td>\n",
       "      <td>282</td>\n",
       "      <td>531</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>06001</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06001400300</td>\n",
       "      <td>2016</td>\n",
       "      <td>1208</td>\n",
       "      <td>1208</td>\n",
       "      <td>912700</td>\n",
       "      <td>912700</td>\n",
       "      <td>2439</td>\n",
       "      <td>1303</td>\n",
       "      <td>1136</td>\n",
       "      <td>443</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>low</td>\n",
       "      <td>06001</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.844702</td>\n",
       "      <td>-122.251371</td>\n",
       "      <td>Rockridge</td>\n",
       "      <td>bart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06001400400</td>\n",
       "      <td>2016</td>\n",
       "      <td>1584</td>\n",
       "      <td>1584</td>\n",
       "      <td>848900</td>\n",
       "      <td>848900</td>\n",
       "      <td>1798</td>\n",
       "      <td>1090</td>\n",
       "      <td>708</td>\n",
       "      <td>189</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>06001</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06001400500</td>\n",
       "      <td>2016</td>\n",
       "      <td>1438</td>\n",
       "      <td>1438</td>\n",
       "      <td>683500</td>\n",
       "      <td>683500</td>\n",
       "      <td>1643</td>\n",
       "      <td>1034</td>\n",
       "      <td>609</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>low</td>\n",
       "      <td>06001</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tract_id  year median_rent median_rent_adj_x median_house_price  \\\n",
       "0  06001400100  2016        3202              2000            1074100   \n",
       "1  06001400200  2016        1770              1770             978900   \n",
       "2  06001400300  2016        1208              1208             912700   \n",
       "3  06001400400  2016        1584              1584             848900   \n",
       "4  06001400500  2016        1438              1438             683500   \n",
       "\n",
       "  median_hp_adj_x housing_units rented_units owned_units over_mln  ...   max  \\\n",
       "0         1000000          1292          128        1164      665  ...   NaN   \n",
       "1          978900           813          282         531      253  ...   NaN   \n",
       "2          912700          2439         1303        1136      443  ...   NaN   \n",
       "3          848900          1798         1090         708      189  ...   NaN   \n",
       "4          683500          1643         1034         609       75  ...   NaN   \n",
       "\n",
       "   low county_id county_name     city all_cities        lat         long  \\\n",
       "0          06001    Alameda   Oakland        NaN        NaN          NaN   \n",
       "1          06001    Alameda   Oakland        NaN        NaN          NaN   \n",
       "2  low     06001    Alameda   Oakland        NaN  37.844702  -122.251371   \n",
       "3          06001    Alameda   Oakland        NaN        NaN          NaN   \n",
       "4  low     06001    Alameda   Oakland        NaN        NaN          NaN   \n",
       "\n",
       "        name  type  \n",
       "0        NaN   NaN  \n",
       "1        NaN   NaN  \n",
       "2  Rockridge  bart  \n",
       "3        NaN   NaN  \n",
       "4        NaN   NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write to Excel as we need trailing 0s in tract ids in order to join with geo data in Tableau\n",
    "writer = ExcelWriter('all_new.xls')\n",
    "df_all.to_excel(writer, sheet_name = 'all')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> County data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def county(file, file2, year):\n",
    "    # load breakdown rent data\n",
    "    df = pd.read_csv(file, header = 1)\n",
    "    \n",
    "    # load median rent data\n",
    "    df_median = pd.read_csv(file2, header = 1)\n",
    "    \n",
    "    # combine dataframes\n",
    "    #df = pd.concat([df, df_median['Estimate; Median gross rent']], axis =1)\n",
    "    df = df.merge(df_median, on = ['Id', 'Id2', 'Geography'], how = 'left')\n",
    "    \n",
    "    # isolate 5 digit country code\n",
    "    #df['Id'] = df.Id.str.slice(9,14)\n",
    "    \n",
    "    # remove 'Estimate;' from column names\n",
    "    df2 = df.iloc[0:9 , 3:]\n",
    "    df2 = df2.rename(columns={col: col.split(';')[1] for col in df2.columns})\n",
    "    \n",
    "    # remove 'With cash rent: -' from column names\n",
    "    df3 = df2.iloc[0:9, 2:(len(df2.columns)-2)]\n",
    "    df3 = df2.rename(columns={col: col.split(': -')[1] for col in df3.columns})\n",
    "    \n",
    "    # remove California and country from the names\n",
    "    df['Geography'] = df.Geography.str.split(' County,').str.get(0)\n",
    "    \n",
    "    # isolate county id and name columns\n",
    "    df = df.iloc[0:9, [0,2]]\n",
    "    \n",
    "    # merge cleaned colum names with county id column\n",
    "    df_county = pd.concat([df, df3], axis = 1)  \n",
    "    \n",
    "    # add year\n",
    "    df_county['year'] = year\n",
    "    \n",
    "    return df_county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "county_2016 = county('ACS_16_5YR_B25063_with_ann.csv', 'ACS_16_5YR_B25064_with_ann.csv', '2016')\n",
    "county_2013 = county('ACS_13_5YR_B25063_with_ann.csv', 'ACS_13_5YR_B25064_with_ann.csv', '2013')\n",
    "county_2010 = county('ACS_10_5YR_B25063_with_ann.csv', 'ACS_10_5YR_B25064_with_ann.csv', '2010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine dfs\n",
    "counties_list = [county_2016, county_2013, county_2010]\n",
    "\n",
    "# concatenate dfs\n",
    "counties = pd.concat(counties_list, ignore_index = True)\n",
    "\n",
    "# calculate %-change in median rent between 2010 and 2016\n",
    "changes = get_changes(counties_list, 'rent_change', ' Median gross rent_x', ' Median gross rent', 'Id', False)\n",
    "\n",
    "# add new columns to all_county\n",
    "counties = counties.merge(changes, on = ['Id'], how='left')\n",
    "\n",
    "# only keep needed columns\n",
    "counties = counties[['Geography', 'Id', ' Median gross rent', 'rent_change', 'year']]\n",
    "\n",
    "# only keep rows for 2016\n",
    "counties = counties[counties.year == '2016']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>NEW - Median rent and median income for the US, state of CA and all counties in the US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from http://code.activestate.com/recipes/577305-python-dictionary-of-us-states-and-territories/\n",
    "states = {\n",
    "        'AK': 'Alaska','AL': 'Alabama','AR': 'Arkansas','AS': 'American Samoa','AZ': 'Arizona','CA': 'California',\n",
    "        'CO': 'Colorado','CT': 'Connecticut','DC': 'District of Columbia','DE': 'Delaware','FL': 'Florida',\n",
    "        'GA': 'Georgia','GU': 'Guam','HI': 'Hawaii','IA': 'Iowa','ID': 'Idaho','IL': 'Illinois', 'IN': 'Indiana',\n",
    "        'KS': 'Kansas','KY': 'Kentucky','LA': 'Louisiana','MA': 'Massachusetts','MD': 'Maryland','ME': 'Maine',\n",
    "        'MI': 'Michigan','MN': 'Minnesota','MO': 'Missouri','MP': 'Northern Mariana Islands','MS': 'Mississippi',\n",
    "        'MT': 'Montana','NA': 'National','NC': 'North Carolina','ND': 'North Dakota','NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire','NJ': 'New Jersey','NM': 'New Mexico','NV': 'Nevada','NY': 'New York',\n",
    "        'OH': 'Ohio','OK': 'Oklahoma','OR': 'Oregon','PA': 'Pennsylvania','PR': 'Puerto Rico','RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina','SD': 'South Dakota','TN': 'Tennessee','TX': 'Texas','UT': 'Utah','VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands','VT': 'Vermont','WA': 'Washington','WI': 'Wisconsin','WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "         }\n",
    "\n",
    "# create df\n",
    "states_df = pd.DataFrame(states.items(), columns = ['state_code', 'state_name'])\n",
    "\n",
    "# list with county ids\n",
    "county_ids_list = ['06001', '06013', '06041', '06055', '06075', '06081', '06085', '06095', '06097'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import median rent per county in 2016\n",
    "rent_county = pd.read_csv('all_us_counties.csv', header = 1)\n",
    "\n",
    "# replace '-' with 0\n",
    "rent_county = rent_county.apply(lambda x: x.replace('-', 0))\n",
    "\n",
    "# import median income per county in 2016\n",
    "income_county = pd.read_csv('all_income.csv', header = 1)\n",
    "\n",
    "# combine dfs\n",
    "all_county = rent_county.merge(income_county, on = ['Id', 'Id2', 'Geography'], how = 'left')\n",
    "\n",
    "# split Geography column in county name and state\n",
    "split = all_county['Geography'].str.split(', ', expand=True)\n",
    "\n",
    "# name new columns\n",
    "split.columns = [['county_name', 'state']]\n",
    "\n",
    "# add columns to rest of df\n",
    "all_county = pd.concat([all_county, split], axis=1)\n",
    "\n",
    "# remove 'County' from county name\n",
    "all_county['county_name'] = all_county['county_name'].str.split(' County').str.get(0)\n",
    "\n",
    "# replace full state name with 2 letter abbreviation\n",
    "all_county = all_county.merge(states_df, left_on = 'state', right_on = 'state_name', how = 'left')\n",
    "\n",
    "# merge county name with state abbreviation\n",
    "all_county['name'] = all_county['county_name'] + ', '+ all_county['state_code']\n",
    "\n",
    "# rename columns\n",
    "all_county = all_county.rename(index = str, \n",
    "                               columns = {'Estimate; Median gross rent' : 'median_rent',\n",
    "                                          'Median income (dollars); Estimate; Households' : 'median_income'})\n",
    "\n",
    "# add marker for SF Bay area counties\n",
    "all_county['sfba'] = all_county.apply(lambda row: 'sfba' if row['Id'][-5:] in county_ids_list else '', axis=1)\n",
    "\n",
    "# drop colums that are not longer needed\n",
    "all_county = all_county[['Id','median_rent', 'median_income', 'state_code', 'name', 'sfba']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change median rent to integer\n",
    "all_county['median_rent'] = all_county['median_rent'].astype('int64')\n",
    "\n",
    "# add rank based on median rent\n",
    "all_county['rank_rent'] = all_county['median_rent'].rank(ascending=False, method = 'first')\n",
    "all_county['rank_income'] = all_county['median_income'].rank(ascending=False, method = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all_county with counties\n",
    "combined = all_county.merge(counties[['Id', 'rent_change']], on = 'Id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df with data for the state of California and the United States in total\n",
    "df = pd.DataFrame([[63783, 1297, 13.251962, 'California'], \\\n",
    "                   [55322, 949, 12.841855, 'United States']], \\\n",
    "                  columns = ['median_income', 'median_rent', 'rent_change', 'name'])\n",
    "\n",
    "# combine county data with CA and US data\n",
    "combined = combined.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add type (country, state (California), county (California) or sfba (county in SF bay area) othwerwise county\n",
    "combined['type'] = combined.apply(lambda row: 'state' if row['name'] == 'California' \\\n",
    "                      else ('country' if row['name'] == 'United States' \\\n",
    "                            else ('sfba' if row['sfba'] == 'sfba' \\\n",
    "                                  else 'county')), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# export data to csv\n",
    "combined.to_csv('all_counties.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
